{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ],
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "I3g3k3W-qfAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "6vsESFZylO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "id": "Hrdfpmv9nMpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10104a0f-a635-4438-f5c9-962a476dc5fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting markitdown[pdf]\n",
            "  Downloading markitdown-0.1.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown[pdf])\n",
            "  Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting markdownify (from markitdown[pdf])\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20260107-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pdfplumber>=0.11.9 (from markitdown[pdf])\n",
            "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown[pdf])\n",
            "  Downloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.9->markitdown[pdf])\n",
            "  Downloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading markitdown-0.1.5-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, onnxruntime, markdownify, pdfminer-six, magika, pdfplumber, markitdown\n",
            "Successfully installed magika-0.6.3 markdownify-1.2.2 markitdown-0.1.5 onnxruntime-1.24.2 pdfminer-six-20251230 pdfplumber-0.11.9 pypdfium2-5.5.0\n",
            "Collecting langchain_mcp_adapters\n",
            "  Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-4.2.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.10-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.13)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n",
            "Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading langchain_google_genai-4.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.10-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-openai, langchain_mcp_adapters, langchain_google_genai\n",
            "Successfully installed filetype-1.2.0 langchain-openai-1.1.10 langchain_google_genai-4.2.1 langchain_mcp_adapters-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ],
      "metadata": {
        "id": "BUav-7KdaY_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY') # Retrieve Deepseek API key from Colab Secrets"
      ],
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sample CVs"
      ],
      "metadata": {
        "id": "RRbStil_qkQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading sample_cv.pdf\n",
        "The codes below download the sample CV\n"
      ],
      "metadata": {
        "id": "kCENjOq6owDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCCp8DwPF4L",
        "outputId": "b7a4ca5c-dd04-49cf-9417-3da58100fecb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 45.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 46.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 41.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 38.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 62.1MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2akmVn9LODIu",
        "outputId": "6d74aa54-4dc6-427d-ea46-50eb603c35e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ğŸ“„ CV_1.pdf\n",
            "================================================================================\n",
            "|     |     |     |     | John         |           | Smith        |                   |     |     |\n",
            "| --- | --- | --- | --- | ------------ | --------- | ------------ | ----------------- | --- | --- |\n",
            "|     |     |     |     | Marketing    |           | Professional |                   |     |     |\n",
            "|     |     |     |     | + Singapore, | Singapore |              | (cid:209) Kowloon |     |     |\n",
            "Experience\n",
            "|                |                  |     |          |                     |              |            |     | 2020 â€“ | Present |\n",
            "| -------------- | ---------------- | --- | -------- | ------------------- | ------------ | ---------- | --- | ------ | ------- |\n",
            "| Engineer,      | ByteDance        |     |          |                     |              |            |     |        |         |\n",
            "| â€¢ Worked       | in a fast-paced, |     | global   | technology          | environment. |            |     |        |         |\n",
            "| â€¢ Collaborated | across           |     | teams to | support large-scale |              | platforms. |     |        |         |\n",
            "â€¢ Applied analytical and problem-solving skills in production systems.\n",
            "Education\n",
            "| McGill   | University |       |              |     |     |     |     | Graduated | 2009 |\n",
            "| -------- | ---------- | ----- | ------------ | --- | --- | --- | --- | --------- | ---- |\n",
            "| Bachelor | of Science | (BSc) | in Marketing |     |     |     |     |           |      |\n",
            "Skills\n",
            "| Content | Creation | SEO | Social | Media |     |     |     |     |     |\n",
            "| ------- | -------- | --- | ------ | ----- | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_2.pdf\n",
            "================================================================================\n",
            "| Minh | Pham |     |     |     |     |     |\n",
            "| ---- | ---- | --- | --- | --- | --- | --- |\n",
            "Design Professional\n",
            "| Beijing,     | China | Hong     | Kong     |               |        |              |                |\n",
            "| ------------ | ---------------- | -------- | ------------- | ------ | ------------ | -------------- |\n",
            "| Professional | Experience       |          |               |        |              |                |\n",
            "| Manager,     | BCG              |          |               |        |              | 2022 â€“ Present |\n",
            "| â€¢ Led        | cross-functional | teams on | client-facing | design | initiatives. |                |\n",
            "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
            "| â€¢ Applied | design thinking | to business | and | strategy | problems. |             |\n",
            "| --------- | --------------- | ----------- | --- | -------- | --------- | ----------- |\n",
            "| Analyst,  | Tencent         |             |     |          |           | 2013 â€“ 2017 |\n",
            "â€¢ Conducted market and product analysis to support decision-making.\n",
            "| â€¢ Collaborated | with    | design and   | engineering | teams.      |     |     |\n",
            "| -------------- | ------- | ------------ | ----------- | ----------- | --- | --- |\n",
            "| â€¢ Produced     | reports | and insights | for senior  | leadership. |     |     |\n",
            "Education\n",
            "| BSc in         | Design  |      |     |     |     | 2011 |\n",
            "| -------------- | ------- | ---- | --- | --- | --- | ---- |\n",
            "| The University | of Hong | Kong |     |     |     |      |\n",
            "Skills\n",
            "| â€¢ UI/UX | Design |     |     |     |     |     |\n",
            "| ------- | ------ | --- | --- | --- | --- | --- |\n",
            "â€¢ Prototyping\n",
            "| â€¢ Graphic | Design |     |     |     |     |     |\n",
            "| --------- | ------ | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_3.pdf\n",
            "================================================================================\n",
            "| Wei Zhang    |              |           |     |     |     | Munich, Germany   |\n",
            "| ------------ | ------------ | --------- | --- | --- | --- | ----------------- |\n",
            "| Consulting   | Professional |           |     |     |     | Sydney (Hometown) |\n",
            "| Professional | Experience   |           |     |     |     |                   |\n",
            "| 2013         | â€“ Present    | Engineer, | PwC |     |     |                   |\n",
            "â€¢ Supportedconsultingengagementsacrossmultipleclient\n",
            "projects.\n",
            "|     |     | â€¢ Performed | data analysis | to inform | strategic recommen- |     |\n",
            "| --- | --- | ----------- | ------------- | --------- | ------------------- | --- |\n",
            "dations.\n",
            "|     |     | â€¢ Collaborated  | with         | cross-functional | teams in | a profes- |\n",
            "| --- | --- | --------------- | ------------ | ---------------- | -------- | --------- |\n",
            "|     |     | sional services | environment. |                  |          |           |\n",
            "Education\n",
            "| 2015 |     | BSc in Consulting |          |     |     |     |\n",
            "| ---- | --- | ----------------- | -------- | --- | --- | --- |\n",
            "|      |     | University        | of Tokyo |     |     |     |\n",
            "Skills\n",
            "| Analytical |     |     | Data Analysis,       | Problem | Solving |     |\n",
            "| ---------- | --- | --- | -------------------- | ------- | ------- | --- |\n",
            "| Business   |     |     | Strategy, PowerPoint |         |         |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_4.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- | --- | --- |\n",
            "Legal Professional\n",
            "| Singapore    | (Hometown) | | Singapore              |           | / Philippines |             |        |             |     |         |\n",
            "| ------------ | ---------- | ------------------------ | --------- | ------------- | ----------- | ------ | ----------- | --- | ------- |\n",
            "| Professional |            | Experience               |           |               |             |        |             |     |         |\n",
            "| 2021         | â€“ 2027     | Senior                   | Engineer, | Microsoft     |             |        |             |     |         |\n",
            "|              |            | â€¢ Led compliance-focused |           |               | initiatives | within | large-scale |     | techni- |\n",
            "cal teams.\n",
            "â€¢ Advisedonregulatory,legal,andriskconsiderationsforcom-\n",
            "plex systems.\n",
            "|     |     | â€¢ Worked | at the | intersection |     | of law, | technology, | and | gover- |\n",
            "| --- | --- | -------- | ------ | ------------ | --- | ------- | ----------- | --- | ------ |\n",
            "nance.\n",
            "| 2020 | â€“ 2023 | Consultant, | StartupXYZ |               |     |            |                 |     |      |\n",
            "| ---- | ------ | ----------- | ---------- | ------------- | --- | ---------- | --------------- | --- | ---- |\n",
            "|      |        | â€¢ Provided  | legal      | and strategic |     | consulting | for early-stage |     | com- |\n",
            "panies.\n",
            "|     |     | â€¢ Supported | contract | review, |     | compliance, | and operational |     | risk |\n",
            "| --- | --- | ----------- | -------- | ------- | --- | ----------- | --------------- | --- | ---- |\n",
            "management.\n",
            "|     |     | â€¢ Engaged | with | cross-functional |     | and | international | stakehold- |     |\n",
            "| --- | --- | --------- | ---- | ---------------- | --- | --- | ------------- | ---------- | --- |\n",
            "ers.\n",
            "Education\n",
            "2021\n",
            "|     |     | PhD in   | Legal      | Studies |     |     |     |     |     |\n",
            "| --- | --- | -------- | ---------- | ------- | --- | --- | --- | --- | --- |\n",
            "|     |     | Tsinghua | University |         |     |     |     |     |     |\n",
            "Skills\n",
            "|     |     | Compliance,   | Litigation, |           | Contract | Review    |     |     |     |\n",
            "| --- | --- | ------------- | ----------- | --------- | -------- | --------- | --- | --- | --- |\n",
            "|     |     | Web3, Machine |             | Learning, | Quantum  | Computing |     |     |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_5.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- |\n",
            "AI Professional\n",
            "| London     | | Hong Kong | | Singapore | (Hometown) |              |               |                |               |\n",
            "| ---------- | ----------- | ----------- | ---------- | ------------ | ------------- | -------------- | ------------- |\n",
            "| Core       | Skills      |             |            | Professional | Experience    |                |               |\n",
            "| Machine    | Learning    | & AI        |            | Senior       | Engineer      |                |               |\n",
            "|            |             |             |            | EY           |               |                | Current       |\n",
            "| â€¢ Advanced | AI Systems  |             |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Designed   | and evaluated | AI-driven      | solutions for |\n",
            "|            |             |             |            | enterprise   | clients.      |                |               |\n",
            "| â€¢ Machine  | Learning    | (ML)        |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Applied    | ML techniques | to large-scale | business      |\n",
            "| â€¢ Natural  | Language    | Processing  | (NLP)      | problems.    |               |                |               |\n",
            "Consultant\n",
            "| Frameworks   | &   | Tools |     |             |             |          |             |\n",
            "| ------------ | --- | ----- | --- | ----------- | ----------- | -------- | ----------- |\n",
            "|              |     |       |     | StartupXYZ  |             |          | 2019 â€“ 2021 |\n",
            "| â€¢ TensorFlow |     |       |     | â€¢ Provided  | AI and data | strategy | advisory to |\n",
            "|              |     |       |     | early-stage | companies.  |          |             |\n",
            "â€¢ PyTorch\n",
            "Senior Analyst\n",
            "|     |     |     |     | DataForge |     | 2016 | â€“ Present |\n",
            "| --- | --- | --- | --- | --------- | --- | ---- | --------- |\n",
            "â€¢ Python\n",
            "|     |     |     |     | â€¢ Conducted | advanced | data analysis | and model |\n",
            "| --- | --- | --- | --- | ----------- | -------- | ------------- | --------- |\n",
            "evaluation.\n",
            "Lead Scientist\n",
            "Education\n",
            "|     |     |     |     | UrbanFlow |     |     | 2010 â€“ 2017 |\n",
            "| --- | --- | --- | --- | --------- | --- | --- | ----------- |\n",
            "PhD in Artificial Intelligence â€¢ Led research initiatives in applied AI systems.\n",
            "| University | of Tokyo |     |     |            |                    |                |     |\n",
            "| ---------- | -------- | --- | --- | ---------- | ------------------ | -------------- | --- |\n",
            "| 2012       |          |     |     | â€¢ Mentored | junior researchers | and engineers. |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ],
      "metadata": {
        "id": "VA2GvPWTQFt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check which tools that the MCP server provide"
      ],
      "metadata": {
        "id": "5mbkH9xHXfmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0311KbN9A3",
        "outputId": "5039d0a1-eb30-4c7e-a946-94d97f15ce82"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search_facebook_users\n",
            "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
            "\n",
            "Args:\n",
            "    q: Search query string (case-insensitive, matches any part of display name)\n",
            "       Examples: \"John\", \"john smith\", \"Smith\"\n",
            "    limit: Maximum number of results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of user dictionaries, each containing:\n",
            "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
            "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
            "    - city (str): Current city of residence\n",
            "    - country (str): Country of residence\n",
            "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_facebook_users(\"Alex Chan\", limit=5)\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
            "    personal information, location, and social connections. Handles typos and variations.\n",
            "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_profile\n",
            "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
            "\n",
            "Args:\n",
            "    user_id: Facebook user ID obtained from search_facebook_users()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): Facebook user ID\n",
            "    - display_name (str): Public display name (may be nickname)\n",
            "    - original_name (str): Original/legal name from LinkedIn\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - hometown (str|None): City/region where user grew up\n",
            "    - bio (str): Personal biography/interests\n",
            "    - status (str|None): Relationship status (Single, Married, etc.)\n",
            "    - education (str|None): Highest education level\n",
            "    - current_job (str|None): Current job title\n",
            "    - current_company (str|None): Current employer\n",
            "    - interests (str): Comma-separated hobbies/interests\n",
            "    - friends (List[int]): List of friend user IDs\n",
            "    - posts (List[dict]): Recent posts with id and content\n",
            "    \n",
            "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_facebook_profile(123)\n",
            "    â†’ {\n",
            "        \"id\": 123,\n",
            "        \"display_name\": \"Sam Chan\",\n",
            "        \"original_name\": \"Alex Chan\",\n",
            "        \"city\": \"Hong Kong\",\n",
            "        \"hometown\": \"Kowloon\",\n",
            "        \"bio\": \"Software professional | Photography enthusiast\",\n",
            "        \"status\": \"Married\",\n",
            "        \"current_job\": \"Senior Engineer\",\n",
            "        \"current_company\": \"Google\",\n",
            "        \"friends\": [124, 125, 126],\n",
            "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Verify candidate's personal details, check for name discrepancies,\n",
            "    validate current employment, and assess social connections.\n",
            "{'user_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_mutual_friends\n",
            "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
            "\n",
            "Args:\n",
            "    user_id_1: First Facebook user ID\n",
            "    user_id_2: Second Facebook user ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - user_1_id (int): First user's ID\n",
            "    - user_2_id (int): Second user's ID\n",
            "    - mutual_friends (List[int]): List of shared friend IDs\n",
            "    - mutual_count (int): Number of mutual friends\n",
            "    \n",
            "    Returns {\"error\": \"...\"} if either user not found.\n",
            "\n",
            "Example:\n",
            "    get_facebook_mutual_friends(123, 456)\n",
            "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
            "\n",
            "Use case:\n",
            "    Verify professional or personal relationships claimed in CV/references.\n",
            "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "search_linkedin_people\n",
            "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
            "\n",
            "Args:\n",
            "    q: Search query (matches name, headline, summary, or skill names)\n",
            "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
            "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
            "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
            "    industry: Filter by industry (optional, case-insensitive)\n",
            "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
            "    limit: Maximum results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of profile dictionaries, each containing:\n",
            "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline/title\n",
            "    - industry (str): Industry sector\n",
            "    - location (str): \"City, Country\" format\n",
            "    - years_experience (int): Total years of work experience\n",
            "    - match_type (str): \"exact\" or \"fuzzy\"\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
            "    Use location filter to narrow down results when common names exist. Handles typos.\n",
            "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_profile\n",
            "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): LinkedIn profile ID\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - industry (str): Primary industry\n",
            "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
            "    - years_experience (int): Total years of professional experience\n",
            "    - summary (str): Professional summary/bio\n",
            "    \n",
            "    - skills (List[dict]): Each containing:\n",
            "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
            "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
            "    \n",
            "    - experience (List[dict]): Work history, each containing:\n",
            "        * company (str): Employer name\n",
            "        * title (str): Job title\n",
            "        * seniority (str): Level (junior, mid, senior)\n",
            "        * start_year (int): Employment start year\n",
            "        * end_year (int|None): Employment end year (None if current)\n",
            "        * is_current (bool): Whether currently employed here\n",
            "    \n",
            "    - education (List[dict]): Academic history, each containing:\n",
            "        * school (str): Institution name\n",
            "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
            "        * field (str): Field of study\n",
            "        * start_year (int): Start year\n",
            "        * end_year (int): Graduation year\n",
            "    \n",
            "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_profile(456)\n",
            "    â†’ {\n",
            "        \"id\": 456,\n",
            "        \"name\": \"Alex Chan\",\n",
            "        \"headline\": \"Senior Software Engineer\",\n",
            "        \"years_experience\": 8,\n",
            "        \"skills\": [\n",
            "            {\"name\": \"Python\", \"proficiency\": 5},\n",
            "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
            "        ],\n",
            "        \"experience\": [\n",
            "            {\n",
            "                \"company\": \"Google\",\n",
            "                \"title\": \"Senior Engineer\",\n",
            "                \"seniority\": \"senior\",\n",
            "                \"start_year\": 2020,\n",
            "                \"end_year\": None,\n",
            "                \"is_current\": True\n",
            "            }\n",
            "        ],\n",
            "        \"education\": [\n",
            "            {\n",
            "                \"school\": \"HKUST\",\n",
            "                \"degree\": \"BSc\",\n",
            "                \"field\": \"Computer Science\",\n",
            "                \"start_year\": 2010,\n",
            "                \"end_year\": 2014\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Primary tool for CV verification - compare claimed experience, education,\n",
            "    skills, and employment dates against LinkedIn ground truth.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_interactions\n",
            "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - profile_id (int): The person's LinkedIn ID\n",
            "    - post_count (int): Number of posts made\n",
            "    - total_likes (int): Total likes received across all posts\n",
            "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
            "    - engagement_score (float): Likes per post ratio\n",
            "    \n",
            "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_interactions(456)\n",
            "    â†’ {\n",
            "        \"profile_id\": 456,\n",
            "        \"post_count\": 10,\n",
            "        \"total_likes\": 150,\n",
            "        \"liked_by\": [123, 124, 125],\n",
            "        \"engagement_score\": 15.0\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Assess professional network strength and content engagement.\n",
            "    Verify connections to claimed colleagues or industry peers.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ],
      "metadata": {
        "id": "ABoe2-qfXl7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Define a local tool\n",
        "# ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ğŸ‘‹\"\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load MCP tools + merge\n",
        "# ---------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "tools = mcp_tools + [say_hello]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize Gemini (tool-enabled) or deepseek\n",
        "# ---------------------------\n",
        "# llm = ChatGoogleGenerativeAI(\n",
        "#     model=\"gemini-2.0-flash\",\n",
        "#     google_api_key=GEMINI_VERTEX_API_KEY,\n",
        "#     temperature=0,\n",
        "# )\n",
        "\n",
        "# DEEPSEEK_API_KEY = userdata.get(\"DEEPSEEK_API_KEY\") # This line is moved to ueILmCPHci9v\n",
        "llm = ChatOpenAI(\n",
        "    model=\"deepseek-chat\",          # or \"deepseek-reasoner\"\n",
        "    api_key=DEEPSEEK_API_KEY,\n",
        "    base_url=\"https://aihubmix.com/v1\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Single-step invocation\n",
        "# ---------------------------\n",
        "query = \"Say hello to Bao using tool, then search for someone named Alice on Facebook.\"\n",
        "\n",
        "response = llm_with_tools.invoke([\n",
        "    HumanMessage(content=query)\n",
        "])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtTjwFKhTKn3",
        "outputId": "95978811-8248-442e-f243-be0ba02e8481"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"I'll help you with that! First, let me say hello to Bao, and then search for Alice on Facebook.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 2940, 'total_tokens': 3008, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 2880}}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'fdc5959e-71a4-47d5-8c7b-c95e2b1027ea', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019c93ae-61fb-77a2-95f5-ea63f22962e0-0' tool_calls=[{'name': 'say_hello', 'args': {'name': 'Bao'}, 'id': 'call_00_7htQJNxSLcUhX7bDaPNW4OMD', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 2940, 'output_tokens': 68, 'total_tokens': 3008, 'input_token_details': {'cache_read': 2880}, 'output_token_details': {}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1: Search Facebook users (exact match)\n",
        "R1 = await tools[0].ainvoke({'q': \"Alex Chan\", 'limit': 5})\n",
        "print(\"Test 1 - search_facebook_users (exact match):\")\n",
        "print(R1)\n",
        "\n",
        "# Test 2: Search Facebook users (fuzzy match with typo)\n",
        "R2 = await tools[0].ainvoke({'q': 'Alx Chn', 'limit': 5, 'fuzzy': True})\n",
        "print(\"Test 2 - search_facebook_users (fuzzy match):\")\n",
        "print(R2)\n",
        "\n",
        "# Test 3: Get Facebook profile\n",
        "R3 = await tools[1].ainvoke({'user_id': 123})\n",
        "print(\"Test 3 - get_facebook_profile:\")\n",
        "print(R3)\n",
        "\n",
        "# Test 4: Get Facebook mutual friends\n",
        "R4 = await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "print(\"Test 4 - get_facebook_mutual_friends:\")\n",
        "print(R4)\n",
        "\n",
        "# Test 5: Search LinkedIn people (exact match)\n",
        "R5 = await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "print(\"Test 5 - search_linkedin_people (exact match):\")\n",
        "print(R5)\n",
        "\n",
        "# Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "R6 = await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
        "print(\"Test 6 - search_linkedin_people (fuzzy match):\")\n",
        "print(R6)\n",
        "\n",
        "# Test 7: Get LinkedIn profile\n",
        "R7 = await tools[4].ainvoke({'person_id': 456})\n",
        "print(\"Test 7 - get_linkedin_profile:\")\n",
        "print(R7)\n",
        "\n",
        "# Test 8: Get LinkedIn interactions\n",
        "R8 = await tools[5].ainvoke({'person_id': 456})\n",
        "print(\"Test 8 - get_linkedin_interactions:\")\n",
        "print(R8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLeoXGrqesW",
        "outputId": "e669627d-6cca-4ac8-8986-2d81b669f704"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1 - search_facebook_users (exact match):\n",
            "[{'type': 'text', 'text': '[{\"id\":3,\"display_name\":\"Alex Chan\",\"city\":\"Hyderabad\",\"country\":\"India\",\"match_type\":\"exact\"},{\"id\":41,\"display_name\":\"Alex Chan\",\"city\":\"Shanghai\",\"country\":\"China\",\"match_type\":\"exact\"},{\"id\":79,\"display_name\":\"Alex Chan\",\"city\":\"London\",\"country\":\"UK\",\"match_type\":\"exact\"},{\"id\":106,\"display_name\":\"Alex Chan\",\"city\":\"Ho Chi Minh City\",\"country\":\"Vietnam\",\"match_type\":\"exact\"},{\"id\":117,\"display_name\":\"Alex Chan\",\"city\":\"Melbourne\",\"country\":\"Australia\",\"match_type\":\"exact\"}]', 'id': 'lc_cb28f586-b710-4f95-bf6e-643fed0cdc1f'}]\n",
            "Test 2 - search_facebook_users (fuzzy match):\n",
            "[{'type': 'text', 'text': '[{\"id\":3,\"display_name\":\"Alex Chan\",\"city\":\"Hyderabad\",\"country\":\"India\",\"match_type\":\"fuzzy\"},{\"id\":41,\"display_name\":\"Alex Chan\",\"city\":\"Shanghai\",\"country\":\"China\",\"match_type\":\"fuzzy\"},{\"id\":79,\"display_name\":\"Alex Chan\",\"city\":\"London\",\"country\":\"UK\",\"match_type\":\"fuzzy\"},{\"id\":106,\"display_name\":\"Alex Chan\",\"city\":\"Ho Chi Minh City\",\"country\":\"Vietnam\",\"match_type\":\"fuzzy\"},{\"id\":117,\"display_name\":\"Alex Chan\",\"city\":\"Melbourne\",\"country\":\"Australia\",\"match_type\":\"fuzzy\"}]', 'id': 'lc_49113db4-3d89-4073-ba98-83033023df5a'}]\n",
            "Test 3 - get_facebook_profile:\n",
            "[{'type': 'text', 'text': '{\"id\":123,\"display_name\":\"Emily Davis\",\"original_name\":\"Emily Davis\",\"city\":\"London\",\"country\":\"UK\",\"hometown\":\"London\",\"bio\":\"Price audience both east scientist.  Eye beyond kind range event coach any him\",\"status\":\"Divorced\",\"education\":\"Master\\'s Degree\",\"current_job\":\"Analyst\",\"current_company\":\"NextGen AI\",\"interests\":\"Reading, Wine Tasting, Running, Hiking\",\"friend_count\":44,\"friends\":[5,12,9122,7234,290,9733,9576,9100,7917,9358,3759,6540,8753,243,8950,4214,5110,8470,1630,365,697,1446,1900,2679,2745,2892,3775,3783,4398,4441,4664,4866,5495,5754,6583,6788,7241,7745,7982,8283,9004,9388,9507,9976],\"posts\":[{\"id\":689,\"content\":\"Good vibes only âœ¨\"},{\"id\":690,\"content\":\"Just got back from London. Already planning my next trip! âœˆï¸\"},{\"id\":691,\"content\":\"Concert vibes in London last night! Best live music ğŸµ\"},{\"id\":692,\"content\":\"First week at NextGen AI complete! Loving the team already ğŸ’¼\"},{\"id\":693,\"content\":\"Celebrating small wins today! ğŸŠ\"},{\"id\":694,\"content\":\"Celebrating small wins today! ğŸŠ\"},{\"id\":695,\"content\":\"Learning so much about UK in London\"},{\"id\":696,\"content\":\"Grateful to be part of an amazing team at NextGen AI ğŸ’¼\"}]}', 'id': 'lc_4151683c-b964-4172-8057-f623c4428b12'}]\n",
            "Test 4 - get_facebook_mutual_friends:\n",
            "[{'type': 'text', 'text': '{\"user_1_id\":123,\"user_2_id\":456,\"mutual_friends\":[],\"mutual_count\":0}', 'id': 'lc_8ff79474-fc34-40f9-b185-fe862fe9ee98'}]\n",
            "Test 5 - search_linkedin_people (exact match):\n",
            "[{'type': 'text', 'text': '[{\"id\":95,\"name\":\"Rahul Sharma\",\"headline\":\"AI Professional\",\"industry\":\"AI\",\"location\":\"Kowloon, Hong Kong\",\"years_experience\":16,\"match_type\":\"exact\"},{\"id\":226,\"name\":\"Amit Patel\",\"headline\":\"Software Professional\",\"industry\":\"Software\",\"location\":\"Central, Hong Kong\",\"years_experience\":4,\"match_type\":\"exact\"},{\"id\":381,\"name\":\"Sophia Ho\",\"headline\":\"AI Professional\",\"industry\":\"AI\",\"location\":\"Sha Tin, Hong Kong\",\"years_experience\":11,\"match_type\":\"exact\"},{\"id\":594,\"name\":\"Michael Cheung\",\"headline\":\"Software Professional\",\"industry\":\"Software\",\"location\":\"Causeway Bay, Hong Kong\",\"years_experience\":15,\"match_type\":\"exact\"},{\"id\":604,\"name\":\"Amit Patel\",\"headline\":\"Software Professional\",\"industry\":\"Software\",\"location\":\"Central, Hong Kong\",\"years_experience\":8,\"match_type\":\"exact\"}]', 'id': 'lc_1df3cdf9-0c4e-4657-9bdd-7a8635e68ada'}]\n",
            "Test 6 - search_linkedin_people (fuzzy match):\n",
            "[{'type': 'text', 'text': '[{\"id\":95,\"name\":\"Rahul Sharma\",\"headline\":\"AI Professional\",\"industry\":\"AI\",\"location\":\"Kowloon, Hong Kong\",\"years_experience\":16,\"match_type\":\"exact\"},{\"id\":226,\"name\":\"Amit Patel\",\"headline\":\"Software Professional\",\"industry\":\"Software\",\"location\":\"Central, Hong Kong\",\"years_experience\":4,\"match_type\":\"exact\"},{\"id\":381,\"name\":\"Sophia Ho\",\"headline\":\"AI Professional\",\"industry\":\"AI\",\"location\":\"Sha Tin, Hong Kong\",\"years_experience\":11,\"match_type\":\"exact\"},{\"id\":594,\"name\":\"Michael Cheung\",\"headline\":\"Software Professional\",\"industry\":\"Software\",\"location\":\"Causeway Bay, Hong Kong\",\"years_experience\":15,\"match_type\":\"exact\"},{\"id\":604,\"name\":\"Amit Patel\",\"headline\":\"Software Professional\",\"industry\":\"Software\",\"location\":\"Central, Hong Kong\",\"years_experience\":8,\"match_type\":\"exact\"}]', 'id': 'lc_3809f5e8-e442-419d-a87f-6e4ef4b8f8f9'}]\n",
            "Test 7 - get_linkedin_profile:\n",
            "[{'type': 'text', 'text': '{\"id\":456,\"name\":\"Michael Cheung\",\"headline\":\"Legal Professional\",\"city\":\"San Francisco\",\"country\":\"USA\",\"industry\":\"Legal\",\"status\":\"student\",\"years_experience\":1,\"summary\":\"Series I American so. Total though military campaign. Way sing international imagine. Carry evidence and economy model account. Check face physical leave strategy behind. What attorney opportunity stand.\",\"skills\":[{\"name\":\"Compliance\",\"proficiency\":1},{\"name\":\"Contract Review\",\"proficiency\":2},{\"name\":\"Litigation\",\"proficiency\":3}],\"experience\":[{\"company\":\"Manulife\",\"title\":\"Engineer\",\"seniority\":\"mid\",\"start_year\":2015,\"end_year\":null,\"is_current\":true},{\"company\":\"Hang Seng Bank\",\"title\":\"Scientist\",\"seniority\":\"senior\",\"start_year\":2017,\"end_year\":2022,\"is_current\":true}],\"education\":[{\"school\":\"City University of Hong Kong\",\"degree\":\"BSc\",\"field\":\"Legal\",\"start_year\":2017,\"end_year\":2020}]}', 'id': 'lc_5d1dcfbc-519f-47ae-98b9-d5734ba6a426'}]\n",
            "Test 8 - get_linkedin_interactions:\n",
            "[{'type': 'text', 'text': '{\"profile_id\":456,\"post_count\":4,\"total_likes\":5,\"liked_by\":[4390,3622,7500,4269,8464],\"engagement_score\":1.25}', 'id': 'lc_e0e67563-4aa2-4102-86c8-486a9ded4627'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ],
      "metadata": {
        "id": "UqO99iOlq6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "scores = []\n",
        "\n",
        "for cv_data in all_cvs:\n",
        "    cv_text = cv_data['text']\n",
        "    query = f\"Please evaluate the following CV for its general validity and completeness. Provide a confidence score between 0.0 and 1.0. Respond only with a JSON object: {{'score': float_value}}.\\n\\nCV Text:\\n{cv_text}\"\n",
        "\n",
        "    # Use the base LLM instance without tools for this specific scoring query\n",
        "    response = llm.invoke([\n",
        "        HumanMessage(content=query)\n",
        "    ])\n",
        "\n",
        "    # Attempt to parse the score from the LLM's response\n",
        "    try:\n",
        "        # Extract JSON string from potential markdown block\n",
        "        json_match = re.search(r\"```json\\n([\\s\\S]*?)\\n```\", response.content)\n",
        "        if json_match:\n",
        "            json_string = json_match.group(1)\n",
        "        else:\n",
        "            json_string = response.content # Assume it's direct JSON if no markdown block\n",
        "\n",
        "        score_dict = json.loads(json_string)\n",
        "        score = float(score_dict.get('score', 0.0)) # Default to 0 if score not found\n",
        "        # Ensure score is within [0, 1]\n",
        "        score = max(0.0, min(1.0, score))\n",
        "    except (json.JSONDecodeError, ValueError) as e:\n",
        "        print(f\"Could not parse score for {cv_data['file']}, defaulting to 0.5. Error: {e}. Response: {response.content}\")\n",
        "        score = 0.5 # Default score if parsing fails\n",
        "\n",
        "    scores.append(score)\n",
        "\n",
        "print(f\"Generated scores: {scores}\")\n",
        "\n",
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J14ltXjPtaMF",
        "outputId": "e8cfdb39-2e3b-46ce-affb-27acf4bf6753"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated scores: [0.4, 0.65, 0.3, 0.2, 0.2]\n",
            "{'decisions': [0, 1, 0, 0, 0], 'correct': 3, 'total': 5, 'final_score': 0.6}\n"
          ]
        }
      ]
    }
  ]
}